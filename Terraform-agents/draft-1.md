# Solution Architecture Overview

We propose a **Temporal-based orchestration** system composed of a central “Terraform Server” and multiple **agent** instances running in Docker. The server uses a Temporal workflow engine (Go SDK) to manage jobs, while each agent is a standalone worker that can execute Terraform CLI commands. Agents register back to the server using a *secure token*, joining an agent **pool** much like Terraform Cloud’s agents do[[1]](https://developer.hashicorp.com/terraform/cloud-docs/agents/agents#:~:text=The%20agent%20software%20runs%20on,an%20HCP%20Terraform%20agent%20pool). The server’s Temporal workflows dispatch tasks (Terraform runs) to available agents via **Task Queues**. Each job is handled by one agent process (with the option to run multiple concurrent processes per host)[[2]](https://developer.hashicorp.com/terraform/cloud-docs/agents/agents#:~:text=Each%20agent%20process%20runs%20a,single%20instance%2C%20license%20limit%20permitting). This decoupled design ensures resiliency: Temporal guarantees durable execution with built-in retries and state recovery, so transient failures (agent crashes, network blips, etc.) do not corrupt the workflow[[3]](https://medium.com/%40surajsub_68985/building-an-infrastructure-stack-using-temporal-terraform-on-aws-d2210b9f6582#:~:text=Terraform%20for%20Infrastructure%20as%20Code,face%20of%20potential%20connection%20interruptions)[[4]](https://temporal.io/resources/on-demand/temporal-hashicorp#:~:text=HashiCorp%20found%20Temporal%20to%20be,Nomad%20cluster%20management%20more%20realiable).

*Figure: Temporal workflow execution model (source: Temporal blog*[*[5]*](https://temporal.io/blog/workflow-engine-principles#:~:text=The%20basic%20idea%20of%20Temporal,as%20in%20this%20Java%20sample)*). Temporal lets us define durable workflows in code, so each Terraform run can be a workflow (with child workflows or activities) that survives restarts or timeouts.*

Agents run entirely in your network and only need **outbound** connectivity to the server/Temporal cluster (no inbound ports needed)[[6]](https://developer.hashicorp.com/terraform/cloud-docs/agents#:~:text=The%20agent%20requires%20only%20outbound,or%20exceptions%20are%20typically%20needed). On startup, an agent uses its token to “call home” and register with the server, which assigns it to a pool. The agent then launches a Temporal **worker process** in Go, listening on the queue for its pool. The server’s Temporal workflow will schedule the Terraform job (as a Workflow or Activity) on that queue, and any idle agent in the pool will pick it up. In effect, Temporal handles the queuing and reliability, while the agents handle the actual Terraform execution.

## Agent Registration and Pools

Each agent is a Dockerized Go application that starts by registering to the Terraform Server. Using a provided **secure token** (like TFC\_AGENT\_TOKEN), the agent calls the server’s registration API and joins a named agent pool. (This mirrors Terraform Cloud’s design where “the token you provide when starting the agent assigns it to an HCP Terraform agent pool”[[1]](https://developer.hashicorp.com/terraform/cloud-docs/agents/agents#:~:text=The%20agent%20software%20runs%20on,an%20HCP%20Terraform%20agent%20pool).) The server keeps track of the pool membership and the agent’s capabilities (e.g. OS/architecture). We recommend ensuring all agents in a pool share the same architecture and Terraform version to avoid incompatibilities[[7]](https://developer.hashicorp.com/terraform/cloud-docs/agents/requirements#:~:text=You%20can%20deploy%20agents%20to,HCP%20Terraform%20Agent%20Docker%20container).

Once registered, the agent spawns a Temporal worker listening on a **TaskQueue** dedicated to its pool. (For example, pool linux\_amd64 → queue terraform\_agent\_pool\_linux\_amd64.) When the server’s workflow schedules an activity on that queue, any agent in that pool can dequeue and run it. By default the agent worker can run one Terraform run at a time per process (as in Terraform Cloud agents)[[2]](https://developer.hashicorp.com/terraform/cloud-docs/agents/agents#:~:text=Each%20agent%20process%20runs%20a,single%20instance%2C%20license%20limit%20permitting), but you can configure the worker to allow multiple goroutines (processes) for higher throughput. In practice, you might run multiple agent containers on the same machine (or multiple worker threads) to handle concurrent runs, respecting resource limits.

Agents are designed to be **resilient and stateless**. They continuously poll the server (via the Temporal task queue) for new jobs. If an agent process crashes or is killed, Temporal will detect the missed heartbeat and can re-assign the task to another agent according to retry policies. This “call home” model with only outbound connectivity keeps private networks secure[[6]](https://developer.hashicorp.com/terraform/cloud-docs/agents#:~:text=The%20agent%20requires%20only%20outbound,or%20exceptions%20are%20typically%20needed).

## Temporal Workflow Orchestration

The **Terraform Server** itself uses Temporal to orchestrate runs. A user or service initiates a Terraform job (for example, via an API call to the server), which starts a Temporal workflow. This workflow embodies the high-level run steps (e.g. plan → apply) and handles failures, logging, and state. Within the workflow code (written in Go), we use Temporal Activities to execute tasks on agents.

For each Terraform job, the server’s workflow does something like:

1. **Select Pool/Agent**: Determine which agent pool to use (e.g. based on Terraform version or tags).
2. **Dispatch Task to Agent**: Use workflow.ExecuteActivity or workflow.StartChildWorkflow with TaskQueue set to the chosen agent queue. The input includes the VCS repo, workspace config, variables, etc. Temporal will deliver this task to one agent worker.
3. **Wait for Completion**: The workflow pauses until the agent activity completes or fails. If it fails, Temporal can retry the activity on another agent (up to a limit) or escalate.
4. **Handle Results**: Once the activity returns, the workflow processes the result (success/failure, logs, new state) and updates system state (e.g. mark job done, store outputs).

By coding workflows this way, we get Temporal’s **retries, timeouts, and history** for free[[8]](https://temporal.io/resources/on-demand/temporal-hashicorp#:~:text=workflow%20engine%20from%20HashiCorp%2C%20but,save%20them%20time%20and%20effort)[[4]](https://temporal.io/resources/on-demand/temporal-hashicorp#:~:text=HashiCorp%20found%20Temporal%20to%20be,Nomad%20cluster%20management%20more%20realiable). For example, if the agent performing terraform apply crashes halfway, the workflow will see the failure (after heartbeat timeout) and can re-run or abort cleanly. The workflow itself is long-running and durable: it can sleep, wait for external signals, or even be restarted from any point. In short, Temporal ensures our Terraform run orchestrations are **fault-tolerant and observable**[[4]](https://temporal.io/resources/on-demand/temporal-hashicorp#:~:text=HashiCorp%20found%20Temporal%20to%20be,Nomad%20cluster%20management%20more%20realiable).

## Terraform Job Execution by Agents

On the agent side, each Terraform job is executed by running the Terraform CLI inside an isolated workspace. The typical sequence in an agent activity might be:

* **Prepare Workspace**: Create a new temporary directory for this run and clone or fetch the Terraform config (Git repo, modules, etc.). (We follow the recommendation that “each execution occurs in its own temporary directory with a clean environment”[[9]](https://developer.hashicorp.com/terraform/cloud-docs/agents/agents#:~:text=Agents%20do%20not%20guarantee%20a,only%20runs%20a%20single%20workload).) This avoids leftover state or files from previous runs interfering.
* **Initialize Terraform**: Run terraform init. If using a remote state backend (see next section), this sets up access to the backend. Otherwise, it initializes the working directory.
* **Run Plan**: Optionally run terraform plan -out=plan.tfplan. Collect the output. (The agent may stream logs back to the server during execution, e.g. via Temporal activity heartbeats or by writing to a shared log store.)
* **Run Apply**: If approved, run terraform apply -auto-approve plan.tfplan (or apply directly). Capture the stdout/stderr output.
* **Collect Logs**: All Terraform CLI output, as well as agent logs, should be captured. The agent can send log lines back to the server (e.g. via Streaming RPC or Temporal heartbeat details) or upload them after completion. Note: Terraform Cloud agents simply write logs to stdout/stderr[[10]](https://developer.hashicorp.com/terraform/cloud-docs/agents/logging#:~:text=HCP%20Terraform%20Agents%20write%20log,with%20a%20process%20or%20container), so we must capture these (e.g. by redirecting to files or buffers). The agent should label logs (INFO/DEBUG etc.) and can support JSON format if needed for log systems.
* **Return Results**: When the run finishes, the agent activity returns a result object containing status (success/fail), any outputs (like terraform output values), and the updated state file (see below). The workflow resumes with this data.

Throughout this process, the agent runs as a Go program invoking Terraform (usually via os/exec). Using Go keeps the system consistent, and the Go Temporal SDK integrates the activity execution. The agent container bundles the Terraform binary, Go runtime, and our code. We recommend instrumenting the agent with metrics (CPU/memory usage) and a process supervisor so it auto-restarts on crash. Since each Terraform run can consume 2+ GB RAM[[11]](https://developer.hashicorp.com/terraform/cloud-docs/agents/requirements#:~:text=The%20host%20running%20the%20agent,each%20workspace%27s%20usage%20and%20performance), the agent host should have sufficient resources.

## State Management

Terraform requires a *state file* to track resource metadata. In our design, we treat agents as **stateless executors**: they load any existing state at the start of a run and return the new state at the end, but do not permanently store state locally. There are two common approaches:

* **Remote Backends**: Configure Terraform to use a remote backend (e.g. AWS S3, Azure Blob, HashiCorp Consul, or Terraform Cloud’s remote backend). In this mode, the agent’s terraform init will pull the current state from the remote store, and apply will push the updated state back automatically[[12]](https://spacelift.io/blog/terraform-architecture#:~:text=resources%20are%20not%20unnecessarily%20recreated,across%20multiple%20runs%20of%20Terraform). The agent need only handle credentials for that backend. (The workflow can pass the backend config and credentials to the agent.)
* **State Pass-Through**: Alternatively, run Terraform with a local state file and have the agent send back the resulting .tfstate to the server. For example, after apply, the agent could read terraform.tfstate and return it (or upload it) as an output of the activity. The server then stores it (e.g. in a database or object store). On the next run, the server would send that state back to the agent before running terraform apply. This ensures the server “owns” the state.

Either way, **the server ultimately stores the canonical state**. In Terraform Cloud, the remote backend can both execute operations and store state[[13]](https://developer.hashicorp.com/terraform/language/backend/remote#:~:text=The%20remote%20backend%20is%20unique,backend), but in our self-hosted design we likely only store state. The key is that agents **do not need to persist state between runs** – after finishing, they clean up their workspace. We then rely on the remote backend or our storage to keep state safe.

Regardless of approach, it’s critical to protect state files, as they contain sensitive data. Best practice is to encrypt state at rest and restrict access. Using remote backends (e.g. S3 with DynamoDB locking) is a proven solution[[12]](https://spacelift.io/blog/terraform-architecture#:~:text=resources%20are%20not%20unnecessarily%20recreated,across%20multiple%20runs%20of%20Terraform). For simplicity, our initial design might simply use S3 or a SQL database on the server side. When the server receives the final state from the agent, it should store it with versioning/backups.

## Logging and Monitoring

Agents produce rich logs (Terraform output, and internal events). By default Terraform Cloud agents “write log messages directly to stdout/stderr” and do not persist them[[10]](https://developer.hashicorp.com/terraform/cloud-docs/agents/logging#:~:text=HCP%20Terraform%20Agents%20write%20log,with%20a%20process%20or%20container), so the Terraform Server must capture and store them. In practice, we can stream logs back as part of the Temporal activity (e.g. via periodic heartbeats) or have the agent upload a log archive at job end. The server can then display these logs in the UI or API for users.

Key logging considerations:
- **Log Levels**: Support levels (INFO, DEBUG, etc.) so users can adjust verbosity (Terraform Cloud agents support -log-level flags)[[14]](https://developer.hashicorp.com/terraform/cloud-docs/agents/logging#:~:text=The%20volume%20of%20logs%20and,levels%20supported%20by%20the%20agent).
- **Structured vs Text**: Optionally emit JSON logs for easier parsing (as HCP agents allow)[[15]](https://developer.hashicorp.com/terraform/cloud-docs/agents/logging#:~:text=It%20is%20also%20possible%20to,and%20looks%20something%20like%20this).
- **Search & Storage**: Centralize logs (e.g. send to Elasticsearch or CloudWatch) if needed. But at minimum, logs should be attached to the job record so users can download them.
- **Monitoring**: Instrument agents with metrics (CPU, memory) and health checks. Temporal’s visibility can show which jobs are running and their status. Retries and timeouts (e.g. abort if stuck) are managed by Temporal.

## Implementation Details

* **Language (Go)**: We use the Go SDK for Temporal to write both server workflows and agent activities. The agent code itself is a Go program (with Terraform CLI invoked via exec.Command). This keeps a single-language stack.
* **Concurrency**: Each agent container can run multiple Terraform processes if needed. We can configure the Temporal worker’s MaxConcurrentActivityExecutionSize to allow N concurrent activities (each one would spawn a separate Terraform CLI process). However, Terraform itself is not thread-safe on shared directories, so each activity must use its own temp dir.
* **Docker Deployment**: The agent Docker image includes: the Go binary, Terraform binary(s), and any plugins. On start, it reads AGENT\_TOKEN and calls the server to register. Then it enters a loop waiting for tasks (polling Temporal). HashiCorp’s official agent container uses a supervisor, but our Go process can run in foreground since Temporal worker loops indefinitely.
* **Security**: Agents authenticate with the server via a token. Use TLS for all agent-server communication. The token should be limited to join only a specific pool. Agents have only outbound API/Temporal calls; the server never needs to SSH into the agent. Keep tokens confidential (e.g. Kubernetes Secret or environment var in Docker).

## Summary

In summary, our solution leverages **Temporal’s durable workflows** to coordinate Terraform runs across a pool of containerized agents. Each agent self-registers to the server with a secure token (just outbound connections needed)[[1]](https://developer.hashicorp.com/terraform/cloud-docs/agents/agents#:~:text=The%20agent%20software%20runs%20on,an%20HCP%20Terraform%20agent%20pool)[[6]](https://developer.hashicorp.com/terraform/cloud-docs/agents#:~:text=The%20agent%20requires%20only%20outbound,or%20exceptions%20are%20typically%20needed), then executes Terraform CLI commands in isolation. The server’s Temporal workflows dispatch jobs to agents (via task queues) and handle state, retries, and logging. Terraform Cloud’s agent model provides guidance: one run per agent process (multiple processes per host)[[2]](https://developer.hashicorp.com/terraform/cloud-docs/agents/agents#:~:text=Each%20agent%20process%20runs%20a,single%20instance%2C%20license%20limit%20permitting), isolated workspaces[[9]](https://developer.hashicorp.com/terraform/cloud-docs/agents/agents#:~:text=Agents%20do%20not%20guarantee%20a,only%20runs%20a%20single%20workload), and stdout log capture[[10]](https://developer.hashicorp.com/terraform/cloud-docs/agents/logging#:~:text=HCP%20Terraform%20Agents%20write%20log,with%20a%20process%20or%20container). By storing state remotely (or via the server)[[12]](https://spacelift.io/blog/terraform-architecture#:~:text=resources%20are%20not%20unnecessarily%20recreated,across%20multiple%20runs%20of%20Terraform) and relying on Temporal’s orchestration, we get a robust, self-healing system: if an agent fails mid-run, the workflow can retry elsewhere, and no state is lost. Overall, this design blends Terraform’s IaC model with Temporal’s workflow engine to create a scalable, reliable **agent-based Terraform execution platform**[[3]](https://medium.com/%40surajsub_68985/building-an-infrastructure-stack-using-temporal-terraform-on-aws-d2210b9f6582#:~:text=Terraform%20for%20Infrastructure%20as%20Code,face%20of%20potential%20connection%20interruptions)[[4]](https://temporal.io/resources/on-demand/temporal-hashicorp#:~:text=HashiCorp%20found%20Temporal%20to%20be,Nomad%20cluster%20management%20more%20realiable).

**Sources:** Official Terraform Enterprise/Cloud agent docs[[1]](https://developer.hashicorp.com/terraform/cloud-docs/agents/agents#:~:text=The%20agent%20software%20runs%20on,an%20HCP%20Terraform%20agent%20pool)[[2]](https://developer.hashicorp.com/terraform/cloud-docs/agents/agents#:~:text=Each%20agent%20process%20runs%20a,single%20instance%2C%20license%20limit%20permitting)[[10]](https://developer.hashicorp.com/terraform/cloud-docs/agents/logging#:~:text=HCP%20Terraform%20Agents%20write%20log,with%20a%20process%20or%20container)[[6]](https://developer.hashicorp.com/terraform/cloud-docs/agents#:~:text=The%20agent%20requires%20only%20outbound,or%20exceptions%20are%20typically%20needed), Terraform state management guidance[[12]](https://spacelift.io/blog/terraform-architecture#:~:text=resources%20are%20not%20unnecessarily%20recreated,across%20multiple%20runs%20of%20Terraform)[[13]](https://developer.hashicorp.com/terraform/language/backend/remote#:~:text=The%20remote%20backend%20is%20unique,backend), and Temporal documentation and case studies[[3]](https://medium.com/%40surajsub_68985/building-an-infrastructure-stack-using-temporal-terraform-on-aws-d2210b9f6582#:~:text=Terraform%20for%20Infrastructure%20as%20Code,face%20of%20potential%20connection%20interruptions)[[8]](https://temporal.io/resources/on-demand/temporal-hashicorp#:~:text=workflow%20engine%20from%20HashiCorp%2C%20but,save%20them%20time%20and%20effort)[[4]](https://temporal.io/resources/on-demand/temporal-hashicorp#:~:text=HashiCorp%20found%20Temporal%20to%20be,Nomad%20cluster%20management%20more%20realiable).

[[1]](https://developer.hashicorp.com/terraform/cloud-docs/agents/agents#:~:text=The%20agent%20software%20runs%20on,an%20HCP%20Terraform%20agent%20pool) [[2]](https://developer.hashicorp.com/terraform/cloud-docs/agents/agents#:~:text=Each%20agent%20process%20runs%20a,single%20instance%2C%20license%20limit%20permitting) [[9]](https://developer.hashicorp.com/terraform/cloud-docs/agents/agents#:~:text=Agents%20do%20not%20guarantee%20a,only%20runs%20a%20single%20workload) Install and run HCP Terraform agents | Terraform | HashiCorp Developer

<https://developer.hashicorp.com/terraform/cloud-docs/agents/agents>

[[3]](https://medium.com/%40surajsub_68985/building-an-infrastructure-stack-using-temporal-terraform-on-aws-d2210b9f6582#:~:text=Terraform%20for%20Infrastructure%20as%20Code,face%20of%20potential%20connection%20interruptions) Building an Infrastructure Stack using Temporal+Terraform on AWS | by Suraj Subramanian | Medium

[https://medium.com/@surajsub\_68985/building-an-infrastructure-stack-using-temporal-terraform-on-aws-d2210b9f6582](https://medium.com/%40surajsub_68985/building-an-infrastructure-stack-using-temporal-terraform-on-aws-d2210b9f6582)

[[4]](https://temporal.io/resources/on-demand/temporal-hashicorp#:~:text=HashiCorp%20found%20Temporal%20to%20be,Nomad%20cluster%20management%20more%20realiable) [[8]](https://temporal.io/resources/on-demand/temporal-hashicorp#:~:text=workflow%20engine%20from%20HashiCorp%2C%20but,save%20them%20time%20and%20effort) Using Temporal at Hashicorp | Temporal

<https://temporal.io/resources/on-demand/temporal-hashicorp>

[[5]](https://temporal.io/blog/workflow-engine-principles#:~:text=The%20basic%20idea%20of%20Temporal,as%20in%20this%20Java%20sample) Workflow Engine Design Principles with Temporal | Temporal

<https://temporal.io/blog/workflow-engine-principles>

[[6]](https://developer.hashicorp.com/terraform/cloud-docs/agents#:~:text=The%20agent%20requires%20only%20outbound,or%20exceptions%20are%20typically%20needed) HCP Terraform agents | Terraform | HashiCorp Developer

<https://developer.hashicorp.com/terraform/cloud-docs/agents>

[[7]](https://developer.hashicorp.com/terraform/cloud-docs/agents/requirements#:~:text=You%20can%20deploy%20agents%20to,HCP%20Terraform%20Agent%20Docker%20container) [[11]](https://developer.hashicorp.com/terraform/cloud-docs/agents/requirements#:~:text=The%20host%20running%20the%20agent,each%20workspace%27s%20usage%20and%20performance) HCP Terraform agent requirements | Terraform | HashiCorp Developer

<https://developer.hashicorp.com/terraform/cloud-docs/agents/requirements>

[[10]](https://developer.hashicorp.com/terraform/cloud-docs/agents/logging#:~:text=HCP%20Terraform%20Agents%20write%20log,with%20a%20process%20or%20container) [[14]](https://developer.hashicorp.com/terraform/cloud-docs/agents/logging#:~:text=The%20volume%20of%20logs%20and,levels%20supported%20by%20the%20agent) [[15]](https://developer.hashicorp.com/terraform/cloud-docs/agents/logging#:~:text=It%20is%20also%20possible%20to,and%20looks%20something%20like%20this) HCP Terraform agent logging | Terraform | HashiCorp Developer

<https://developer.hashicorp.com/terraform/cloud-docs/agents/logging>

[[12]](https://spacelift.io/blog/terraform-architecture#:~:text=resources%20are%20not%20unnecessarily%20recreated,across%20multiple%20runs%20of%20Terraform) Terraform Architecture Overview – Structure and Workflow

<https://spacelift.io/blog/terraform-architecture>

[[13]](https://developer.hashicorp.com/terraform/language/backend/remote#:~:text=The%20remote%20backend%20is%20unique,backend) Backend Type: remote | Terraform | HashiCorp Developer

<https://developer.hashicorp.com/terraform/language/backend/remote>

